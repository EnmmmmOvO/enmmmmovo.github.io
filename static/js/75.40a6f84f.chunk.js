"use strict";(self.webpackChunkhome=self.webpackChunkhome||[]).push([[75],{5075:e=>{e.exports=JSON.parse('{"home":"Home","about":"About","contact":"Contact","projects":"Projects","name":"Jinghan Wang","morning":"Good Morning, ","afternoon":"Good Afternoon, ","evening":"Good Evening, ","welcome":"Welcome to my website!","aboutme":"About Me","website":"Website","paper":"Paper","friend":"Friend Link","portfolios":"Portfolios","source":"Source code","jumpTitle":"Potential Delay in Server Response","jumpContent":"The website takes a slight delay in receiving responses from the service. Consequently, if there is no immediate reaction upon clicking buttons, please be patient and wait for a while.","jumpButton":"I understand","jumpDismiss":"Don\'t show this again","project":[{"logo":"react.png","type":"React","title":"My Airbnb","description":"Web application for Property Trading similar to #:aAirbnb[https://www.airbnb.com.au/]#.","content":[{"type":"title","content":"Feature Description:"},{"type":"text","content":"This project designed to provide a convenient intermediary platform for landlords and renters, allows landlords to publicly share their property information, while renters can easily browse, search, and book these listings. Specifically, the app supports the following features:"},{"type":"list","content":["User Registration and Login","Uploading Property Photos and Information","Search and Filter Functionality","Online Booking Functionality"]},{"type":"title","content":"Technology Stack:"},{"type":"text","content":"This project was my first major assignment using the React framework. I adopted TypeScript to ensure high code quality and maintainability. For routing management, I used React Router\'s BrowserRouter component to create a dynamic and responsive single-page application (SPA). Due to the minimal need for global state, I chose React\'s Context API over Redux for state management, which met the application\'s needs while keeping the architecture simple."},{"type":"text","content":"In terms of interface design, I used Material UI (MUI) as the main UI framework, which not only sped up development but also ensured a modern and responsive look for the application."},{"type":"text","content":"To ensure code stability and quality, as per the assignment requirements, I used Jest for unit testing three key components. Additionally, I used Cypress for end-to-end UI testing to ensure overall application stability and user experience."},{"type":"text","content":"Overall, this project enhanced my front-end development skills, especially in using React and related technology stacks. A shortcoming, however, was the tight coupling of multiple components within the React framework due to extensive data interactions between different components. This strategy avoided complex management of global state to some extent but reduced code reusability and limited testing convenience. In future projects, a more refined component division is needed to reduce inter-component coupling and enhance code maintainability, testability, and scalability."}],"link":"https://enmmmmovo.github.io/Airbnb/","repo":"https://github.com/EnmmmmOvO/Airbnb","imageSize":60,"image":["airbnb/logo.svg","airbnb/1.png","airbnb/2.png","airbnb/3.png","airbnb/4.png","airbnb/5.png","airbnb/6.png","airbnb/7.png"]},{"logo":"kaggle.png","type":"Neural Network","title":"Stable Diffusion - Image to Prompts","description":"Generate prompt words that align with the content of the input images.","content":[{"type":"title","content":"Project Concept and Model Selection"},{"type":"text","content":"This project is inspired by a #:aKaggle[https://www.kaggle.com/competitions/stable-diffusion-image-to-prompts]# competition. We selected two distinct models for implementation and comparative analysis: the #:iCLIP# model and the #:iResnet + LSTM# model. The objective was to train both models separately and then conduct a macro-level comparison to evaluate their strengths and weaknesses."},{"type":"title","content":"Model Training and Optimization"},{"type":"text","content":"Each model was built upon its respective pre-trained framework. We employed the Adam optimizer and a learning rate scheduler during the training process to facilitate model convergence and enhance the overall training results. For both models, the test and validation sets were sourced from the #:iDiffusionDB# dataset in #:aHugging Face[https://huggingface.co/datasets/poloclub/diffusiondb]#, following adequate preprocessing."},{"type":"title","content":"My Contribution - #:iResnet + LSTM# Model"},{"type":"text","content":"As a member of the team, my responsibility was to implement and train the #:Resnet + LSTM# model. The primary process involved:"},{"type":"list","content":["#:bFeature Extraction#: Utilizing the #:iResNet-50# model to extract features from input images.","#:bFeature Mapping#: Mapping these extracted features to the input dimensions of the #:iGPT-2# model through a linear layer.","#:bText Generation#: Processing these features via an #:iLSTM# layer to generate an initial textual description of the image.","#:bText Refinement#: Using the #:iGPT-2# model to refine the initial description into a comprehensive final image description."]},{"type":"text","content":"The entire training procedure for my part was conducted on Kaggle\'s #:iGPU-P100#."},{"type":"title","content":"Training Outcome and Analysis"},{"type":"text","content":"After about 7 epochs of training, the loss metric of the #:iResnet + LSTM# model plateaued and did not show further improvement. In comparison with the #:iCLIP# model, there was a notable variance from the actual original prompts. The potential reasons identified for this discrepancy are:"},{"type":"list","content":["#:bModel Architecture#: The project required the handling of both images and text. The #:iCNN# (Convolutional Neural Network) was employed for image processing and the #:iRNN# (Recurrent Neural Network) for text processing. The interlinking layer, designed to map the output of the #:iCNN# to the input of the #:iRNN#, might have been too rigid. This potentially led to less effective feature extraction and integration compared to the #:ViT# model in #:CLIP#, known for its efficient image-text correspondence.","#:bParameter Optimization and Time Constraints#: Limited time for the project might have resulted in insufficient adjustment and optimization of certain model parameters. This could have contributed to the challenges faced in achieving effective convergence during the training process."]}],"repo":"https://github.com/GATA-Chen/COMP9417_Project","paper":"http://3.25.181.130/documents/9417%20Report.pdf","imageSize":80,"image":["imageToPrompt/logo.svg","imageToPrompt/1.png","imageToPrompt/2.png","imageToPrompt/3.png","imageToPrompt/4.png"]},{"logo":"fastapi.svg","type":"FastAPI + React","title":"CONEX","description":"Web Platform for Connecting Professionals with Projects","content":[],"imageSize":80,"image":["conex/logo.svg"]}],"portfolio":[]}')}}]);